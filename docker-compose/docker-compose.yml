version: "2.1"

services:
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    ports:
      - "2181:2181"
    #volumes:
    #  - "zookeeper_data:/bitnami"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: docker.io/bitnami/kafka:3.1.2
    ports:
      - "9092:9092"
    #volumes:
    #  - "kafka_data:/bitnami"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
    depends_on:
      - zookeeper

  # Solved including KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true in kafka
  # To create the topic flight_delay_classification_request
  # This service execute command and exit with code 0
  # kafka-init:
  #   image: docker.io/bitnami/kafka:3.3
  #   depends_on:
  #     - kafka
  #   entrypoint: [ 'bin/sh', '-c' ]
  #   command: |
  #     "
  #     # blocks until kafka is reachable
  #     sleep 5

  #     echo -e 'Creating kafka topics'
  #     kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic flight_delay_classification_request --replication-factor 1 --partitions 1

  #     echo -e 'Successfully created the following topics:'
  #     kafka-topics.sh --bootstrap-server kafka:9092 --list
  #     "
      
  webapp:
    build: "./webapp"
    ports:
      - "5000:5000"
    environment:
      - MONGODB=mongodb
      - KAFKA=kafka

  mongodb:
    image: "mongo"
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_DATABASE=agile_data_science #Access with mongodb://admin:password@127.0.0.1:27017/agile_data_science
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password

  mongodb-init:
    image: "mongo"
    depends_on:
      - mongodb
    entrypoint: [ 'bin/sh', '-c' ]
    command: |
      "
      # blocks until mongodb is reachable
      sleep 5

      apt-get update
      apt-get install -y curl

      echo -e 'Downloading data'
      curl -Lko ./origin_dest_distances.jsonl http://s3.amazonaws.com/agile_data_science/origin_dest_distances.jsonl

      echo -e 'Importing resources'
      mongoimport --authenticationDatabase=admin --uri="mongodb://admin:password@mongodb:27017/agile_data_science" -d agile_data_science -c origin_dest_distances --file origin_dest_distances.jsonl
      mongosh -u "admin" -p "password" mongodb://admin:password@mongodb:27017/agile_data_science --authenticationDatabase "admin" --eval 'db.origin_dest_distances.createIndex({Origin: 1, Dest: 1})'
      "

  spark:
    image: bitnami/spark:3.1.2-debian-10-r130
    user: root
    environment:
      - SPARK_MODE=master
    ports:
      - '8080:8080'
      - '7077:7077'
    volumes:
      #- /home/javier/Escritorio/BDFI/ProyectoFinal/practica_big_data_2019/flight_prediction/target/scala-2.12:/opt/spark-apps
      - shared-volume:/opt/spark-apps
      - ./predictor/jars_dir:/opt/bitnami/spark/ivy:z

  spark-worker:
    build: "./spark-worker"
    deploy:
      replicas: 1
    user: root
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=4
    ports:
      - '8081:8081'

    volumes:
      #- /home/javier/Escritorio/BDFI/ProyectoFinal/practica_big_data_2019/flight_prediction/target/scala-2.12:/opt/spark-apps
      - shared-volume:/opt/spark-apps
      - ./predictor/jars_dir:/opt/bitnami/spark/ivy:z

  init:
    build: "./init"
    user: root
    volumes:
      - shared-volume:/opt/spark-apps

  # spark-init:
  #   image: bitnami/spark:3.1.2-debian-10-r130
  #   user: root
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark:7077
  #   volumes:
  #     #- /home/javier/Escritorio/BDFI/ProyectoFinal/practica_big_data_2019/flight_prediction/target/scala-2.12:/opt/spark-apps
  #     - shared-volume:/opt/spark-apps
  #   depends_on:
  #     - spark
  #   entrypoint: [ 'sh', '-c' ]
  #   command: |
  #     "
  #     #Sleep until sbt compile and package
  #     sleep 10

  #     echo -e 'Starting predictor'
  #     spark-submit --conf spark.jars.ivy=/opt/bitnami/spark/ivy --master spark://spark:7077 --deploy-mode cluster --supervise --class es.upm.dit.ging.predictor.MakePrediction --name FlightPrediction --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 /opt/spark-apps/practicaBD/flight_prediction/target/scala-2.12/flight_prediction_2.12-0.1.jar
  #     "

  config:
    build: "./config"
    volumes:
      - shared-volume:/opt/spark-apps

volumes:
  shared-volume:
#volumes:
#  zookeeper_data:
#    driver: local
#  kafka_data:
#    driver: local
